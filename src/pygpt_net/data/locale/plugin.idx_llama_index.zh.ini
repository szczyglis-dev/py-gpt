[LOCALE]
append_meta.description = 如果启用，将把Llama-index的元数据附加到额外上下文中
append_meta.label = 将元数据追加到上下文中
ask_llama_first.description = 如果启用，将首先询问Llama-index，并将回答作为在prompt中使用的额外知识。禁用时，只在需要时才询问Llama-index。INFO：在自主模式（通过插件）中禁用！
ask_llama_first.label = 首先询问Llama-index
idx.description = 要使用的索引的ID，默认为：base，如果想要同时使用多个索引，请用逗号分隔。
idx.label = 要使用的索引
max_question_chars.description = 查询Llama-index时问题中的最大字符数，0 = 无限制。
max_question_chars.label = 问题中的最大字符数
model_prepare_question.description = 用于在询问Llama-index之前准备问题的模型，默认为：gpt-3.5-turbo
model_prepare_question.label = 准备问题的模型
model_query.description = 用于查询Llama-index的模型，默认为：gpt-3.5-turbo。
model_query.label = 模型
plugin.description = 将Llama-index（文件聊天）存储集成到任何聊天中，并提供来自文件和数据库中上下文历史的额外上下文知识
plugin.name = 文件聊天（Llama-index，内联）
prepare_question.description = 如果启用，在询问Llama-index之前，将准备问题以创建最佳查询。
prepare_question.label = 在首次询问Llama-index之前自动准备问题
prepare_question_max_tokens.description = 在询问Llama-index之前准备问题时输出中的最大令牌数。
prepare_question_max_tokens.label = 准备问题的最大输出令牌数
prompt.description = 用于指导如何使用Llama-index提供的额外数据的提示。
prompt.label = 提示
syntax_prepare_question.description = 准备问题的系统提示。
syntax_prepare_question.label = 准备问题的提示
