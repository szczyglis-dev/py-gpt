[LOCALE]
append_meta.description = If enabled, metadata from Llama-index will be appended to the additional context
append_meta.label = Append metadata to context
ask_llama_first.description = When enabled, Llama-index will be asked first, and the response will be used as additional knowledge in the prompt. When disabled, Llama-index will be asked only when needed. INFO: Disabled in autonomous mode (via plugin)!
ask_llama_first.label = Ask Llama-index first
idx.description = IDs of indexes to use, default: base, separate by comma if you want to use more than one index at once.
idx.label = Indexes to use
max_question_chars.description = Maximum characters in a question when querying Llama-index, 0 = no limit.
max_question_chars.label = Maximum characters in question
model_prepare_question.description = Model used to prepare a question before asking Llama-index, default: gpt-3.5-turbo
model_prepare_question.label = Model for question preparation
model_query.description = Model used for querying Llama-index, default: gpt-3.5-turbo.
model_query.label = Model
plugin.description = Integrates Llama-index (Chat with files) storage in any chat and provides additional knowledge into context (from files and from context history in the database)
plugin.name = Chat with files (Llama-index, inline)
prepare_question.description = When enabled, the question will be prepared before asking Llama-index to create the best query.
prepare_question.label = Auto-prepare question before asking Llama-index first
prepare_question_max_tokens.description = Maximum tokens in output when preparing a question before asking Llama-index.
prepare_question_max_tokens.label = Maximum output tokens for question preparation
prompt.description = Prompt used to instruct how to use additional data provided from Llama-index.
prompt.label = Prompt
syntax_prepare_question.description = System prompt for question preparation.
syntax_prepare_question.label = Prompt for question preparation