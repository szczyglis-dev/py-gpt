[LOCALE]
plugin.name = Chat with files (Llama-index, inline)
plugin.description = Integrates Llama-index (Chat with files) storage in any chat and provides additional knowledge into context (from files and from context history in database)

prompt.label = Prompt
prompt.description = Prompt used for instruct how to use additional data provided from Llama-index
prompt.tooltip = Prompt

ask_llama_first.label = Ask Llama-index first
ask_llama_first.description = When enabled, then Llama-index will be asked first, and response will be used as additional knowledge in prompt. When disabled, then Llama-index will be asked only when needed.
ask_llama_first.tooltip = Ask Llama-index first

prepare_question.label = Auto-prepare question before asking Llama-index first
prepare_question.description = When enabled, then question will be prepared before asking Llama-index first to create best query.
prepare_question.tooltip = When enabled, then question will be prepared before asking Llama-index first to create best query.

model_prepare_question.label = Model for question preparation
model_prepare_question.description = Model used to prepare question before asking Llama-index, default: gpt-3.5-turbo
model_prepare_question.tooltip = Model used to prepare question before asking Llama-index, default: gpt-3.5-turbo

prepare_question_max_tokens.label = Max output tokens for question preparation
prepare_question_max_tokens.description = Max tokens in output when preparing question before asking Llama-index
prepare_question_max_tokens.tooltip = Max tokens in output when preparing question before asking Llama-index

max_question_chars.label = Max characters in question
max_question_chars.description = Max characters in question when querying Llama-index, 0 = no limit
max_question_chars.tooltip = Max characters in question when querying Llama-index, 0 = no limit

syntax_prepare_question.label = Prompt for question preparation
syntax_prepare_question.description = System prompt for question preparation
syntax_prepare_question.tooltip = System prompt for question preparation

model_query.label = Model
model_query.description = Model used for querying Llama-index, default: gpt-3.5-turbo
model_query.tooltip = Model

idx.label = Indexes to use
idx.description = ID's of indexes to use, default: base, separate by comma if you want to use more than one index at once
idx.tooltip = Indexes to use
