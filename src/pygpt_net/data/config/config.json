{
  "__meta__": {
    "version": "2.5.73",
    "app.version": "2.5.73",
    "updated_at": "2025-07-28T00:00:00"
  },
  "access.audio.event.speech": false,
  "access.audio.event.speech.disabled": [],
  "access.audio.notify.execute": true,
  "access.audio.use_cache": true,
  "access.microphone.notify": true,
  "access.shortcuts": [
      {
          "action": "voice_cmd.toggle",
          "key": "Space",
          "key_modifier": "Ctrl"
      },
      {
          "action": "tab.chat",
          "key": "1",
          "key_modifier": "Ctrl"
      },
      {
          "action": "tab.files",
          "key": "2",
          "key_modifier": "Ctrl"
      },
      {
          "action": "tab.calendar",
          "key": "3",
          "key_modifier": "Ctrl"
      },
      {
          "action": "tab.draw",
          "key": "4",
          "key_modifier": "Ctrl"
      },
      {
          "action": "tab.notepad",
          "key": "5",
          "key_modifier": "Ctrl"
      }        
  ],
  "access.voice_control": false,
  "access.voice_control.blacklist": [],
  "access.voice_control.model": "gpt-4o-mini",
  "agent.auto_stop" : true,
  "agent.continue.always": false,
  "agent.func_call.native": false,
  "agent.goal.notify": false,
  "agent.idx": "base",
  "agent.iterations": 3,
  "agent.llama.idx": "base",
  "agent.llama.loop.enabled": false,
  "agent.llama.loop.score": 75,
  "agent.llama.max_eval": 3,
  "agent.llama.provider": "openai",
  "agent.llama.steps": 10,
  "agent.llama.verbose": false,
  "agent.mode": "chat",
  "agent.api_use_responses": false,
  "ai_name": "",
  "api_azure_version": "2023-07-01-preview",
  "api_azure_endpoint": "https://<your-resource-name>.openai.azure.com/",
  "api_endpoint": "https://api.openai.com/v1",
  "api_endpoint_deepseek": "https://api.deepseek.com/v1",
  "api_endpoint_google": "https://generativelanguage.googleapis.com/v1beta/openai",
  "api_endpoint_perplexity": "https://api.perplexity.ai",
  "api_endpoint_xai": "https://api.x.ai/v1",
  "api_endpoint_anthropic": "https://api.anthropic.com/v1",
  "api_endpoint_mistral": "https://api.mistral.ai/v1",
  "api_key": "",
  "api_key_google": "",
  "api_key_anthropic": "",
  "api_key_hugging_face": "",
  "api_key_deepseek": "",
  "api_key_perplexity": "",
  "api_key_xai": "",
  "api_key_mistral": "",
  "api_proxy": "",
  "api_use_responses": true,
  "api_use_responses_llama": false,
  "app.env": [
        {
            "name": "OLLAMA_API_BASE",
            "value": "http://localhost:11434"
        }
    ],
  "assistant": "",
  "assistant_thread": "",
  "assistant.store.hide_threads": true,
  "attachments_auto_index": true,
  "attachments_send_clear": true,
  "attachments_capture_clear": true,
  "audio.input.channels": 1,
  "audio.input.continuous": false,
  "audio.input.device": "0",
  "audio.input.rate": 44100,
  "audio.input.stop_interval": 10,
  "audio.input.timeout": 120,
  "audio.input.timeout.continuous": false,
  "audio.transcribe.convert_video": true,
  "context_threshold": 200,
  "cmd": false,
  "ctx": "",
  "ctx.attachment.img": false,
  "ctx.attachment.mode": "query",
  "ctx.attachment.rag.history": true,
  "ctx.attachment.rag.history.max_items": 3,
  "ctx.attachment.summary.model": "gpt-4o-mini",
  "ctx.attachment.query.model": "gpt-4o-mini",
  "ctx.attachment.verbose": false,
  "ctx.auto_summary": true,
  "ctx.auto_summary.model": "gpt-4o-mini",
  "ctx.convert_lists": false,
  "ctx.counters.all": false,
  "ctx.edit_icons": true,
  "ctx.code_interpreter": true,
  "ctx.list.expanded": [],
  "ctx.records.filter": "all",
  "ctx.records.filter.labels": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7
  ],
  "ctx.records.folders.top": true,
  "ctx.records.limit": 0,
  "ctx.records.separators": true,
  "ctx.records.groups.separators": true,
  "ctx.records.pinned.separators": false,
  "ctx.search_content": true,
  "ctx.search.string": "",
  "ctx.sources": true,
  "ctx.use_extra": true,
  "current_model": {
    "assistant": "gpt-4o-mini",
    "chat": "gpt-4o-mini",
    "completion": "gpt-3.5-turbo-instruct",
    "img": "dall-e-3",
    "langchain": "gpt-4o-mini",
    "llama_index": "gpt-4o-mini",
    "vision": "gpt-4o",
    "agent": "gpt-4o",
    "agent_llama": "gpt-4o",
    "expert": "gpt-4o"
  },
  "current_preset": {
    "assistant": "",
    "chat": "",
    "completion": "",
    "img": "",
    "langchain": "",
    "llama_index": "",
    "vision": "",
    "agent": "",
    "agent_llama": "",
    "expert": ""
  },
  "debug": false,
  "debug.render": false,
  "download.dir": "download",
  "experts.func_call.native": false,
  "experts.mode": "chat",
  "experts.use_agent": false,
  "experts.api_use_responses": false,
  "experts.internal.api_use_responses": false,
  "font_size": 12,
  "font_size.input": 12,
  "font_size.ctx": 12,
  "font_size.toolbox": 12,
  "func_call.native": true,
  "frequency_penalty": 0.0,
  "img_dialog_open": false,
  "img_prompt_model": "gpt-4o",
  "img_raw": true,
  "img_resolution": "1792x1024",
  "img_quality": "standard",
  "img_variants": 1,
  "interpreter.auto_clear": false,
  "interpreter.execute_all": false,
  "interpreter.edit": false,
  "interpreter.input": "",
  "interpreter.ipython": true,
  "lang": "en",
  "layout.animation.disable": false,
  "layout.density": -1,
  "layout.dialog.geometry.store": true,
  "layout.dialog.geometry": {},
  "layout.dpi.scaling": true,
  "layout.dpi.factor": 1.0,
  "layout.groups": {},
  "layout.splitters": {
        "columns": [
            1,
            0
        ]
    },
  "layout.split": false,
  "layout.tabs": {},
  "layout.tooltips": true,
  "layout.tray": true,
  "layout.tray.minimize": false,
  "layout.window": {},
  "license.accepted": false,
  "llama.hub.loaders.args": [],
  "llama.hub.loaders.use_local": false,
  "llama.idx.auto": false,
  "llama.idx.auto.index": "base",
  "llama.idx.auto.modes": "chat,completion,vision,assistant,research,llama_index,agent",
  "llama.idx.chat.agent.render.all": false,
  "llama.idx.chat.auto_retrieve": true,
  "llama.idx.chat.mode": "context",
  "llama.idx.current": null,
  "llama.idx.custom_meta": [
      {
          "extensions": "*",
          "key": "file_name",
          "value": "{relative_path}"
      }
  ],
  "llama.idx.custom_meta.web": [],
  "llama.idx.db.index": "base",
  "llama.idx.db.last": 0,
  "llama.idx.embeddings.provider": "openai",
  "llama.idx.embeddings.args": [
      {
          "name": "model",
          "value": "text-embedding-3-small",
          "type": "str"
      }
  ],
  "llama.idx.embeddings.env": [
      {
          "name": "OPENAI_API_KEY",
          "value": "{api_key}"
      },
      {
          "name": "OPENAI_API_BASE",
          "value": "{api_endpoint}"
      }
  ],
  "llama.idx.embeddings.limit.rpm": 100,
  "llama.idx.excluded.ext": "3g2,3gp,7z,a,aac,aiff,alac,apk,apk,apng,app,ar,avif,bin,cab,class,deb,deb,dll,dmg,dmg,drv,dsd,dylib,dylib,ear,egg,elf,esd,exe,flac,flv,heic,heif,ico,img,iso,jar,ko,lib,lz,lz4,m2v,mpc,msi,nrg,o,ogg,ogv,pcm,pkg,pkg,psd,pyc,rar,rpm,rpm,so,so,svg,swm,sys,vdi,vhd,vhdx,vmdk,vob,war,whl,wim,wma,wmv,xz,zst",
  "llama.idx.excluded.force": false,
  "llama.idx.list": [
      {
          "id": "base",
          "name": "Base"
      }
  ],
  "llama.idx.mode": "chat",
  "llama.idx.react": false,
  "llama.idx.recursive": true,
  "llama.idx.replace_old": true,
  "llama.idx.status": {},
  "llama.idx.stop.error": true,
  "llama.idx.storage": "SimpleVectorStore",
  "llama.idx.storage.args": [],
  "lock_modes": true,
  "log.assistants": false,
  "log.ctx": true,
  "log.dalle": false,
  "log.events": false,
  "log.level": "error",
  "log.llama": false,
  "log.plugins": false,
  "max_output_tokens": 0,
  "max_requests_limit": 60,
  "max_tokens_length": 32000,
  "max_total_tokens": 128000,
  "mode": "chat",
  "model": "gpt-4o",
  "notepad.num": 1,
  "organization_key": "",
  "output_timestamp": false,
  "painter.brush.color": "Black",
  "painter.brush.mode": "brush",
  "painter.brush.size": 3,
  "painter.canvas.size": "1280x720",
  "plugins": {},
  "plugins_enabled": {
    "agent": false,
    "audio_input": false,
    "audio_output": false,
    "cmd_api": false,
    "cmd_code_interpreter": false,
    "cmd_custom": false,
    "cmd_files": false,
    "cmd_history": false,
    "cmd_serial": false,
    "cmd_system": false,
    "cmd_web": false,
    "crontab": false,
    "experts": false,
    "idx_llama_index": false,
    "openai_dalle": false,
    "openai_vision": false,
    "real_time": true,
    "voice_control": false
  },
  "presence_penalty": 0.0,
  "preset": "current.chat",
  "preset.plugins": "",
  "prompt": "",
  "prompt.agent.continue": "Continue, or complete the run if the goal is fully achieved.",
  "prompt.agent.continue.always": "Continue reasoning...",
  "prompt.agent.goal": "## STATUS UPDATE:\n\n- You can use \"goal_update\" special command to update status of the task.\n- Remember to put it in the form as given, at the end of the surrounding <tool></tool> tags, example: <tool>{\"cmd\": \"goal_update\", \"params\": {\"status\": \"finished\"}}</tool>.\n- Attach this special command to response text, at the end, without calling any internal or external tools.\n\n## ON GOAL FINISH:\nWhen you believe that the task has been completed 100% and all goals have been achieved, include \"goal_update\" command  in the response with status = \"finished\".\n\n## ON PAUSE, FAILED OR WAIT:\n\n If more data from user is needed to achieve the goal or task run must be paused or task was failed or when the conversation falls into a loop, THEN STOP REASONING and include \"goal_update\" command in the response with one of these statuses: \"pause\", \"failed\" or \"wait\"",
  "prompt.agent.instruction": "# AUTONOMOUS MODE IS ENABLED:\n\nYou are a helpful Autonomous Agent and an expert in problem-solving.\n\n## Rules:\n\n- You will now enter self-dialogue mode, where you will be conversing with yourself, not with a human.\n- When you enter self-dialogue mode, remember that you are engaging in a conversation with yourself. Any user input will be considered a reply featuring your previous response.\n- The objective of this self-conversation is well-defined\u2014focus on achieving it.\n- Your new message should be a continuation of the last response you generated, essentially replying to yourself and extending it.\n- After each response, critically evaluate its effectiveness and alignment with the goal. If necessary, refine your approach.\n- Incorporate self-critique after every response to capitalize on your strengths and address areas needing improvement.\n- To advance towards the goal, utilize all the strategic thinking and resources at your disposal.\n- Ensure that the dialogue remains coherent and logical, with each response serving as a stepping stone towards the ultimate objective.\n- Treat the entire dialogue as a monologue aimed at devising the best possible solution to the problem.\n- Conclude the self-dialogue upon realizing the goal or reaching a pivotal conclusion that meets the initial criteria.\n- You can use available tools (if available) using <tool>...</tool> tags - remember to always use the appropriate command to run the tool and verify the result of the tool execution.\n- You are allowed to use any commands and tools without asking for it.\n- While using tools, always use the correct syntax and never interrupt the command before generating the full instruction.\n- ALWAYS break down the main task into manageable logical subtasks, systematically addressing and analyzing each one in sequence.\n- With each subsequent response, make an effort to enhance your previous reply by enriching it with new ideas and do it automatically without asking for it.\n- Any input that begins with 'user: ' will come from me, and I will be able to provide you with ANY additional commands or goal updates in this manner. The other inputs, not prefixed with 'user: ' will represent your previous responses.\n- Start by breaking down the task into as many smaller sub-tasks as possible, then proceed to complete each one in sequence.  Next, break down each sub-task into even smaller tasks, carefully and step by step go through all of them until the required goal is fully and correctly achieved.\n- Do not offer additional help at the end - focus on the defined task only. If I need something else, I will ask for it myself.",
  "prompt.agent.llama.eval": "Please review the result below to determine if the agent's response is satisfactory and if the assigned task was completed correctly. Evaluate the quality and accuracy of the response, as well as the successful completion of the task, using a percentage scale from 0% to 100%. Use the tool provided to send feedback to the agent, including instructions addressed directly to him on how to improve the previous result, along with a numerical rating. The instructions should be prepared in the language used by the user.\n\n## Tool for sending feedback:\n\n- send_feedback\n\n## When creating an instruction, please use the following format:\n\n```\nPlease correct and extend your response by including the following:\n\n1. ...\n2. ...\n```\n\n## Content to evaluate:\n\nMAIN TASK:\n\n```\n\n{task}\n\n```\n\nLAST USER INPUT:\n\n```\n\n{input}\n\n```\n\nAGENT RESPONSE:\n\n```\n\n{output}\n\n```\n\n## Additional rules:\n\n- ALWAYS provide the instruction for the agent in the language used by the user in main task description.\n- Do not repeat the suggested improvements if they have already been correctly included in the agent's response.",
  "prompt.cmd": "RUNNING TOOLS:\n\nYou can execute tools and also use them to run commands in the user's environment.\n\nImportant Rules:\n\n1. To execute a tool, return a JSON object with the \"cmd\" key and the tool name as its value.\n2. Always use the syntax defined in the tool definition and the correct tool name.\n3. Put tool parameters in the \"params\" key. Example: `{\"cmd\": \"web_search\", \"params\": {\"query\": \"some query\"}}`. Use ONLY this syntax. DO NOT use any other syntax.\n4. Append the JSON object to the response at the end and surround it with the `<tool>...</tool>` tags. Example: text response `<tool>{\"cmd\": \"web_search\", \"params\": {\"query\": \"some query\"}}</tool>`.\n5. If you want to execute a tool without any response, return only the JSON object.\n6. Responses from tools will be returned in the \"result\" key.\n7. Always use the correct tool name, e.g., if the tool name is \"sys_exec\", then use \"sys_exec\" and don't use other names, like \"run\" or something.\n8. With tools, you have access to the user's local files and you are allowed to run external tools and apps in the user's system (environment).\n9. Always use the defined syntax to prevent errors.\n10. Always choose the most appropriate tool from the list to perform the task, based on the description of the action performed by a given tool.\n11. Reply to the user in the language in which they started the conversation with you.\n12. Use ONLY parameters described in the tool definition; do NOT use any additional parameters not described in the list.\n13. ALWAYS remember that any text content must appear at the beginning of your response, and tools must be included at the end of the response.\n14. Every tool parameter must be placed on one line, so when you generate code you must put all of the code on one line.\n15. Run the tools immediately without asking for permission.\n16. Use the current path by default when accessing files if a full path is not provided.\n17. The list of available tools is defined below, described in the JSON schema.\n\nJSON schema with tools list:\n----------------\n{schema}\n----------------\n{extra}",
  "prompt.cmd.extra": "When executing tools, always use the following JSON syntax:\n<tool>{\"cmd\": \"<tool_name>\", \"params\": {\"<param_name>\": \"<param_value>\"}}</tool>",
  "prompt.cmd.extra.assistants": "IMPORTANT: never execute above tools in your environment. Instead, could you provide me with the JSON syntax for the tool you would use? It will be executed on my system automatically. Always return the tool from above schema in JSON format inside the tags <tool>...</tool>",
  "prompt.ctx.auto_summary.system": "You are an expert in conversation summarization",
  "prompt.ctx.auto_summary.user": "Summarize topic of this conversation in one sentence. Use best keywords to describe it. Summary must be in the same language as the conversation and it will be used for conversation title so it must be EXTREMELY SHORT and concise - use maximum 5 words: \n\nHuman: {input}\nAI Assistant: {output}",
  "prompt.default": "You are a helpful assistant.",
  "prompt.expert": "# EXPERT MODE IS ENABLED:\n\nYou are a very helpful asssistant and the professional manager of a team of experts, each of whom is the best in their respective fields.\n\n## Rules:\n\n- Instead of directly answering questions, you will manage these experts by forwarding queries to them, collecting their responses, controlling the flow of information between them, and sending requests to them.\n- Experts are distinct, specialized AI models running on my local machine.\n- You will serve as a bridge between them.\n- Each expert has their own conversation context, allowing you to communicate with them normally.\n- The experts can communicate with you but not with each other, making you responsible for relaying information between them.\n- Each expert can use tools and commands, for example, reading files or searching the Web. You can ask experts to call tools and commands.\n- After consulting with the experts, your task is to prepare the best possible answer based on the assistance received.\n- To send a request to an expert, prepare the \"expert_call\" tool. Remember to format the JSON tool as shown, surrounding the tool with `<tool></tool>` tags, for example: `<tool>{\"cmd\": \"expert_call\", \"params\": {\"id\": \"expert_id\", \"query\": \"some query\"}}</tool>`. Make sure the JSON object is syntactically correct, without any redundand parenthness.\n- DO NOT call any remote tools when calling the experts.\n- Remember that the call must contain a query and the ID of the expert to whom the query is being forwarded.\n- Use ONLY the experts listed below; DO NOT TRY to ask any non-existent experts\u2014they will not respond.\n- Do not respond to the expert's replies or use the JSON tool again if replying; the expert only has the ability to listen to your queries sent via the JSON command and to respond to them.\n- Always follow ALL user commands, even if you think the expert can't do something. Experts are allowed to execute commands just as you can.\n- After querying an expert, always wait for the expert's response before sending another query.\n- Do not try to query experts in the middle of the conversation; put your queries and commands at the end of the text.\n- Always call only one expert at a time.\n- Always execute only one command at a time.\n- Always use the language used by the user in the conversation.\n- Never write as a called expert and do not imagine a response from them; instead, always wait for the response from the expert.\n- Every message sent to you directly after your query is always a response from the asked expert, not from me.\n- Always send a direct, clear, and detailed prompt to the expert, without any \"Please...\", \"Could you...\", etc.\n- Always forward all the messages that the user wants to send to the expert, without any exceptions.\n-- If a user command appears outside an expert's scope, fulfill the request regardless, without refusal.\n\n## List of allowed experts, along with their IDs:\n\n{presets}",
  "prompt.img": "Convert my query to detailed image generate prompt, without any \"Please generate...\" and etc., just image description only. Return only the prompt, without nothing else.",
  "render.blocks": true,
  "render.engine": "web",
  "render.open_gl": false,
  "render.plain": false,
  "render.code_syntax": "github-dark",
  "remote_tools.web_search": true,
  "remote_tools.image": false,
  "remote_tools.code_interpreter": false,
  "remote_tools.mcp": false,
  "remote_tools.mcp.args": "{\n    \"type\": \"mcp\",\n    \"server_label\": \"deepwiki\",\n    \"server_url\": \"https://mcp.deepwiki.com/mcp\",\n    \"require_approval\": \"never\",\n    \"allowed_tools\": [\"ask_question\"]\n}",
  "remote_tools.file_search": false,  
  "remote_tools.file_search.args": "",
  "remote_tools.computer_use.env": "",
  "send_clear": true,
  "send_mode": 2,
  "store_history": true,
  "store_history_time": true,
  "stream": true,
  "tabs.data": {
      "0": {
          "uuid": "58c017b7-f0a4-4303-af0d-d2d70d8c1b15",
          "pid": 0,
          "idx": 0,
          "type": 0,
          "data_id": 1,
          "title": "Chat",
          "custom_name": false
      },
      "1": {
          "uuid": "2aa07f79-ec0d-4935-b4e0-e0ccb404c96e",
          "pid": 1,
          "idx": 1,
          "type": 2,
          "data_id": null,
          "title": "Files",
          "custom_name": false
      },
      "2": {
          "uuid": "61e1b447-aed7-4678-890c-b44402a019eb",
          "pid": 2,
          "idx": 2,
          "type": 4,
          "data_id": null,
          "title": "Calendar",
          "custom_name": false
      },
      "3": {
          "uuid": "31aa5dfc-d6ce-4bd5-b28d-a5bcabffa506",
          "pid": 3,
          "idx": 3,
          "type": 3,
          "data_id": null,
          "title": "Painter",
          "custom_name": false
      },
      "4": {
          "uuid": "2944f757-2e1c-45b9-8281-2a12e00f3fab",
          "pid": 4,
          "idx": 4,
          "type": 1,
          "data_id": 1,
          "title": "Notepad",
          "custom_name": false
      },
      "5": {
          "uuid": "4e90829a-a2c9-4006-a46e-e18460673948",
          "pid": 5,
          "idx": 0,
          "type": 100,
          "data_id": null,
          "title": "Python Code Interpreter",
          "tooltip": "",
          "custom_name": false,
          "column_idx": 1,
          "tool_id": "interpreter"
      },
      "6": {
          "uuid": "738ea1d1-4b2f-495b-89c7-7bc3ef7e29f9",
          "pid": 6,
          "idx": 1,
          "type": 100,
          "data_id": null,
          "title": "HTML/JS Canvas",
          "tooltip": "",
          "custom_name": false,
          "column_idx": 1,
          "tool_id": "html_canvas"
      }
  },
  "temperature": 1.0,
  "theme": "dark",
  "theme.markdown": true,
  "theme.style": "chatgpt",
  "top_p": 1.0,
  "upload.store": true,
  "upload.data_dir": false,
  "updater.check.launch": true,
  "updater.check.bg": true,
  "updater.check.bg.last_time": "",
  "updater.check.bg.last_version": "",
  "use_context": true,
  "user_name": "",
  "video.player.path": "",
  "video.player.volume": 100,
  "video.player.volume.mute": false,
  "vision.capture.auto": false,
  "vision.capture.enabled": false,
  "vision.capture.height": 720,
  "vision.capture.idx": 0,
  "vision.capture.quality": 95,
  "vision.capture.width": 1280,
  "zoom": 1.0
}